import asyncio
import random
import re
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup


async def scrape_google_maps(url: str, max_reviews: int | None = None) -> list[dict]:
    """Google ãƒãƒƒãƒ—ã‹ã‚‰å£ã‚³ãƒŸã‚’å–å¾—ã™ã‚‹ã€‚max_reviews æŒ‡å®šæ™‚ã¯ãã®ä»¶æ•°ã§æ‰“ã¡åˆ‡ã‚‹ã€‚"""
    limit_msg = f"ï¼ˆä¸Šé™ {max_reviews} ä»¶ï¼‰" if max_reviews else "ï¼ˆå…¨ä»¶ï¼‰"
    print(f"ğŸ—ºï¸  Google ãƒãƒƒãƒ— ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹... {limit_msg}")

    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=True,
            args=[
                "--disable-blink-features=AutomationControlled",
                "--disable-dev-shm-usage",
                "--no-sandbox",
                "--disable-setuid-sandbox",
                "--disable-infobars",
                "--window-size=1280,900",
            ],
        )
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            viewport={"width": 1280, "height": 900},
            locale="ja-JP",
            java_script_enabled=True,
        )
        # webdriver ãƒ•ãƒ©ã‚°ã‚’éš ã—ã¦ãƒœãƒƒãƒˆæ¤œçŸ¥ã‚’å›é¿
        await context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
            Object.defineProperty(navigator, 'plugins', { get: () => [1, 2, 3] });
            Object.defineProperty(navigator, 'languages', { get: () => ['ja-JP', 'ja', 'en-US'] });
            window.chrome = { runtime: {} };
        """)
        page = await context.new_page()

        await page.goto(url, wait_until="domcontentloaded", timeout=60000)
        await asyncio.sleep(3)

        # Cookie åŒæ„ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’é–‰ã˜ã‚‹
        for selector in ['button[aria-label*="åŒæ„"]', 'button[aria-label*="Accept"]']:
            try:
                btn = await page.query_selector(selector)
                if btn:
                    await btn.click()
                    await asyncio.sleep(1)
                    break
            except Exception:
                pass

        # å£ã‚³ãƒŸã‚¿ãƒ–ã‚’ã‚¯ãƒªãƒƒã‚¯
        for selector in [
            'button[aria-label*="ã‚¯ãƒã‚³ãƒŸ"]',
            'button[aria-label*="Reviews"]',
            '[data-tab-index="1"]',
        ]:
            try:
                btn = await page.query_selector(selector)
                if btn:
                    await btn.click()
                    print("  âœ… å£ã‚³ãƒŸã‚¿ãƒ–ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã—ãŸ")
                    break
            except Exception:
                pass

        # å£ã‚³ãƒŸè¦ç´ ãŒå‡ºç¾ã™ã‚‹ã¾ã§å¾…ã¤ï¼ˆæœ€å¤§20ç§’ï¼‰
        print("  â³ å£ã‚³ãƒŸã®èª­ã¿è¾¼ã¿ã‚’å¾…æ©Ÿä¸­...")
        try:
            await page.wait_for_selector('[data-review-id]', timeout=20000)
            print("  âœ… å£ã‚³ãƒŸè¦ç´ ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
        except Exception:
            print("  âš ï¸ å£ã‚³ãƒŸè¦ç´ ã®å¾…æ©Ÿã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€‚ãã®ã¾ã¾ç¶šè¡Œã—ã¾ã™ã€‚")
        await asyncio.sleep(2)

        # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªã‚³ãƒ³ãƒ†ãƒŠã‚’ JS ã§ç‰¹å®š
        scroll_js = """
            () => {
                const review = document.querySelector('[data-review-id]');
                if (!review) return null;
                let el = review.parentElement;
                for (let i = 0; i < 10; i++) {
                    if (!el) break;
                    const style = window.getComputedStyle(el);
                    const ov = style.overflowY;
                    if ((ov === 'auto' || ov === 'scroll') && el.scrollHeight > el.clientHeight + 50) {
                        return el.className.split(' ')[0];
                    }
                    el = el.parentElement;
                }
                return null;
            }
        """
        scroll_container_class = await page.evaluate(scroll_js)
        if scroll_container_class:
            print(f"  ğŸ“Œ ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚³ãƒ³ãƒ†ãƒŠ: .{scroll_container_class}")
        else:
            print("  âš ï¸ ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚³ãƒ³ãƒ†ãƒŠãŒç‰¹å®šã§ãã¾ã›ã‚“")

        print("  â³ å£ã‚³ãƒŸã‚’ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å–å¾—ä¸­...")
        last_count = 0
        stuck = 0

        for i in range(150):
            # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ï¼ˆç‰¹å®šã§ããŸã‚¯ãƒ©ã‚¹å„ªå…ˆã€fallback ã¯ mouse.wheelï¼‰
            try:
                scrolled = await page.evaluate(f"""
                    () => {{
                        const el = document.querySelector('[data-review-id]');
                        if (!el) return false;
                        let c = el.parentElement;
                        for (let i = 0; i < 10; i++) {{
                            if (!c) break;
                            const ov = window.getComputedStyle(c).overflowY;
                            if ((ov === 'auto' || ov === 'scroll') && c.scrollHeight > c.clientHeight + 50) {{
                                c.scrollTop += 3000;
                                return true;
                            }}
                            c = c.parentElement;
                        }}
                        return false;
                    }}
                """)
                if not scrolled:
                    await page.mouse.wheel(0, 3000)
            except Exception:
                await page.mouse.wheel(0, 3000)

            await asyncio.sleep(random.uniform(0.8, 1.5))

            # ã€Œã‚‚ã£ã¨è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’å±•é–‹
            try:
                await page.evaluate("""
                    document.querySelectorAll('button.w8nwRe, button[jsaction*="expandReview"]').forEach(b => b.click());
                """)
            except Exception:
                pass

            soup = BeautifulSoup(await page.content(), "html.parser")
            reviews_now = _parse_google_reviews(soup)
            count = len(reviews_now)

            if (i + 1) % 10 == 0 or count != last_count:
                print(f"    ğŸ“¥ å–å¾—ä»¶æ•°: {count}ä»¶ï¼ˆè©¦è¡Œ {i+1}ï¼‰")

            if max_reviews and count >= max_reviews:
                print(f"  âœ… å–å¾—ä¸Šé™ {max_reviews} ä»¶ã«åˆ°é”ï¼ˆè©¦è¡Œ {i+1}ï¼‰")
                break

            if count <= last_count:
                stuck += 1
                if stuck >= 8:
                    print(f"  âœ… ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«çµ‚ç«¯ã«åˆ°é”ï¼ˆè©¦è¡Œ {i+1}ï¼‰")
                    break
            else:
                stuck = 0
            last_count = count

        soup = BeautifulSoup(await page.content(), "html.parser")
        reviews = _parse_google_reviews(soup)
        if max_reviews:
            reviews = reviews[:max_reviews]
        await browser.close()

    print(f"  âœ… Google ãƒãƒƒãƒ—: {len(reviews)}ä»¶å–å¾—")
    return reviews


def _clean_review_text(text: str) -> str:
    """Google ãƒãƒƒãƒ—ãŒä»˜åŠ ã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆé£Ÿäº‹ã®ç¨®é¡ãƒ»æ–™é‡‘ãƒ»è©•ç‚¹ãªã©ï¼‰ã‚’é™¤å»ã™ã‚‹ã€‚"""
    metadata_markers = [
        r'é£Ÿäº‹ã®ç¨®é¡',
        r'1\s*äººã‚ãŸã‚Šã®æ–™é‡‘',
        r'é£Ÿäº‹[:ï¼š]\s*\d',
        r'ã‚µãƒ¼ãƒ“ã‚¹[:ï¼š]\s*\d',
        r'é›°å›²æ°—[:ï¼š]\s*\d',
        r'äºˆç´„\n',
        r'ã‚°ãƒ«ãƒ¼ãƒ—ã®äººæ•°',
    ]
    pattern = '|'.join(f'(?:{m})' for m in metadata_markers)
    m = re.search(pattern, text)
    if m:
        text = text[:m.start()].strip()
    return text


def _parse_google_reviews(soup: BeautifulSoup) -> list[dict]:
    reviews = []

    # data-review-id ãŒã‚ã‚‹ div ã‚’å„ªå…ˆ
    blocks = soup.find_all("div", {"data-review-id": True})
    if not blocks:
        blocks = soup.find_all("div", class_=re.compile(r"jftiEf"))

    seen = set()
    for block in blocks:
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆï¼ˆè¤‡æ•°ã®ã‚¯ãƒ©ã‚¹åãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œï¼‰
            text_el = block.find(class_=re.compile(r"wiI7pd|MyEned|review-full-text"))
            if not text_el:
                # span ã‚„ div ã®ä¸­ã§æœ€ã‚‚é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¢ã™
                candidates = block.find_all(["span", "p"], string=True)
                text_el = max(candidates, key=lambda x: len(x.get_text()), default=None)
            raw_text = text_el.get_text(strip=True) if text_el else ""
            text = _clean_review_text(raw_text)
            if len(text) < 5 or text in seen:
                continue
            seen.add(text)

            # è©•ç‚¹ï¼ˆaria-label="æ˜Ÿ5ã¤ä¸­4ã¤" ã®ã‚ˆã†ãªå½¢å¼ï¼‰
            rating = 0.0
            for el in block.find_all(attrs={"aria-label": True}):
                label = el.get("aria-label", "")
                m = re.search(r"(\d)(?:\.\d)?(?:ã¤|æ˜Ÿ| star)", label)
                if m:
                    rating = float(m.group(1))
                    break

            # æ—¥ä»˜
            date_el = block.find(class_=re.compile(r"rsqaWe|xRkPPb|review-date"))
            date_str = date_el.get_text(strip=True) if date_el else ""

            # ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼å
            name_el = block.find(class_=re.compile(r"d4r55|reviewer|al6Kxe"))
            reviewer_name = name_el.get_text(strip=True) if name_el else ""

            reviews.append({
                "source": "google_maps",
                "reviewer_name": reviewer_name,
                "rating": rating,
                "date": date_str,
                "text": text,
                "location": "",
            })
        except Exception:
            continue
    return reviews
