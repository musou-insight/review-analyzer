import asyncio
import random
import re
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup


async def scrape_tripadvisor(url: str) -> list[dict]:
    """TripAdvisor ã‹ã‚‰å£ã‚³ãƒŸã‚’å…¨ãƒšãƒ¼ã‚¸å–å¾—ã™ã‚‹ï¼ˆ15ä»¶/ãƒšãƒ¼ã‚¸ï¼‰ã€‚"""
    print("âœˆï¸  TripAdvisor ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹...")
    reviews = []

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            viewport={"width": 1280, "height": 900},
            locale="ja-JP",
        )
        page = await context.new_page()

        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã« URL ãƒ™ãƒ¼ã‚¹ã‚’è§£æ
        # TripAdvisor ã®ãƒšãƒ¼ã‚¸ã¯ URL ã« or{offset}-Reviews ã‚’å«ã‚€
        # ä¾‹: https://www.tripadvisor.jp/Restaurant_Review-g...d...-Reviews-RestaurantName.html
        #      â†’ or15-Reviews ã§ 2 ãƒšãƒ¼ã‚¸ç›®
        base_url = url

        page_num = 1
        offset = 0
        while True:
            if page_num == 1:
                current_url = base_url
            else:
                # or{offset}-Reviews å½¢å¼ã«å¤‰æ›
                if "-Reviews-" in base_url:
                    current_url = base_url.replace("-Reviews-", f"-or{offset}-Reviews-")
                else:
                    break

            print(f"  ğŸ“„ ãƒšãƒ¼ã‚¸ {page_num} ã‚’å–å¾—ä¸­ (offset={offset})")
            try:
                await page.goto(current_url, wait_until="networkidle", timeout=30000)
                await asyncio.sleep(random.uniform(0.5, 1.5))
            except Exception as e:
                print(f"  âš ï¸ ãƒšãƒ¼ã‚¸å–å¾—å¤±æ•—: {e}")
                break

            # ã€Œç¶šãã‚’èª­ã‚€ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦å…¨æ–‡å±•é–‹
            try:
                more_btns = await page.query_selector_all(
                    'button[data-test-target="expand-review"], button.taLnk.ulBlueLinks, span.taLnk'
                )
                for btn in more_btns[:20]:
                    try:
                        await btn.click()
                        await asyncio.sleep(0.3)
                    except Exception:
                        pass
            except Exception:
                pass

            soup = BeautifulSoup(await page.content(), "html.parser")
            new_reviews = _parse_tripadvisor_reviews(soup)

            if not new_reviews:
                print(f"  âœ… çµ‚ç«¯ãƒšãƒ¼ã‚¸ã«åˆ°é”ï¼ˆãƒšãƒ¼ã‚¸ {page_num}ï¼‰")
                break

            reviews.extend(new_reviews)
            print(f"    ğŸ“¥ ãƒšãƒ¼ã‚¸ {page_num}: {len(new_reviews)}ä»¶ / ç´¯è¨ˆ {len(reviews)}ä»¶")

            # æ¬¡ãƒšãƒ¼ã‚¸ç¢ºèª
            next_btn = soup.find("a", attrs={"data-page-number": str(page_num + 1)})
            if not next_btn:
                # aria-label ã§ç¢ºèª
                next_btn = soup.find("a", attrs={"aria-label": re.compile(r"æ¬¡|Next")})
            if not next_btn:
                break

            offset += 15
            page_num += 1
            await asyncio.sleep(random.uniform(1.0, 2.0))

        await browser.close()

    print(f"  âœ… TripAdvisor: {len(reviews)}ä»¶å–å¾—")
    return reviews


def _parse_tripadvisor_reviews(soup: BeautifulSoup) -> list[dict]:
    reviews = []
    # TripAdvisor ã®å£ã‚³ãƒŸãƒ–ãƒ­ãƒƒã‚¯ï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œï¼‰
    blocks = soup.find_all("div", attrs={"data-reviewid": True})
    if not blocks:
        blocks = soup.find_all("div", class_=re.compile(r"review-container|reviewSelector"))
    if not blocks:
        blocks = soup.find_all("div", class_=re.compile(r"_c|SvjLX"))  # æ–° UI

    seen = set()
    for block in blocks:
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆ
            text_el = (
                block.find(class_=re.compile(r"partial_entry|reviewText|biGQs"))
                or block.find("q")
                or block.find("p", class_=re.compile(r"review"))
            )
            text = text_el.get_text(strip=True) if text_el else ""
            if not text or text in seen:
                continue
            seen.add(text)

            # è©•ç‚¹
            rating_el = block.find(attrs={"class": re.compile(r"ui_bubble_rating|bubble_")})
            if not rating_el:
                rating_el = block.find(attrs={"aria-label": re.compile(r"\d.*5|â˜…")})
            rating = 0.0
            if rating_el:
                # class="bubble_50" â†’ 5.0 ã®ã‚ˆã†ãªå½¢å¼
                cls = " ".join(rating_el.get("class", []))
                m = re.search(r"bubble_(\d{2})", cls)
                if m:
                    rating = int(m.group(1)) / 10
                else:
                    aria = rating_el.get("aria-label", "")
                    m2 = re.search(r"(\d(?:\.\d)?)", aria)
                    if m2:
                        rating = float(m2.group(1))

            # æ—¥ä»˜
            date_el = block.find(class_=re.compile(r"ratingDate|date_visited|biGQs.*date"))
            if not date_el:
                date_el = block.find(attrs={"data-prwidget-name": re.compile(r"date")})
            date_str = ""
            if date_el:
                date_str = date_el.get("title", date_el.get_text(strip=True))

            # ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼åãƒ»locationï¼ˆTripAdvisor ã¯ location ã‚’ç›´æ¥å–å¾—ï¼‰
            name_el = block.find(class_=re.compile(r"username|member_info|memberOverlayLink"))
            reviewer_name = name_el.get_text(strip=True) if name_el else ""

            loc_el = block.find(class_=re.compile(r"userLocation|hometown"))
            location = loc_el.get_text(strip=True) if loc_el else ""

            reviews.append({
                "source": "tripadvisor",
                "reviewer_name": reviewer_name,
                "rating": rating,
                "date": date_str,
                "text": text,
                "location": location,
            })
        except Exception:
            continue
    return reviews
