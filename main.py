#!/usr/bin/env python3
"""é£²é£Ÿåº—å£ã‚³ãƒŸåé›†ãƒ»åˆ†æãƒ„ãƒ¼ãƒ« ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆã€‚"""

import argparse
import asyncio
import json
import os
import subprocess
import sys

import nest_asyncio

nest_asyncio.apply()


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="é£²é£Ÿåº—å£ã‚³ãƒŸåé›†ãƒ»åˆ†æãƒ„ãƒ¼ãƒ«",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""ä½¿ç”¨ä¾‹:
  python main.py --name "ãƒ†ã‚¹ãƒˆé£Ÿå ‚" --tripadvisor "https://www.tripadvisor.jp/..."
  python main.py --name "ãƒ†ã‚¹ãƒˆé£Ÿå ‚" --google-maps "https://www.google.com/maps/..." --tabelog "https://tabelog.com/..."
  python main.py --name "ãƒ†ã‚¹ãƒˆé£Ÿå ‚" --skip-scrape   # æ—¢å­˜JSONã‹ã‚‰åˆ†æã®ã¿å†å®Ÿè¡Œ
  python main.py --name "ãƒ†ã‚¹ãƒˆé£Ÿå ‚" --google-maps "..." --max-reviews 200  # å…¨ã‚µã‚¤ãƒˆ200ä»¶ä¸Šé™
""",
    )
    parser.add_argument("--name", default="åº—èˆ—", help="åº—èˆ—åï¼ˆãƒ¬ãƒãƒ¼ãƒˆã®ã‚¿ã‚¤ãƒˆãƒ«ã«ä½¿ç”¨ï¼‰")
    parser.add_argument("--google-maps", dest="google_maps", metavar="URL", help="Google ãƒãƒƒãƒ— URL")
    parser.add_argument("--tabelog", metavar="URL", help="é£Ÿã¹ãƒ­ã‚° URL")
    parser.add_argument("--tripadvisor", metavar="URL", help="TripAdvisor URL")
    parser.add_argument(
        "--skip-scrape",
        action="store_true",
        help="ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã€æ—¢å­˜ã® reviews_raw.json ã‹ã‚‰åˆ†æã®ã¿å®Ÿè¡Œ",
    )
    parser.add_argument("--output", default="report.html", help="å‡ºåŠ› HTML ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: report.htmlï¼‰")
    parser.add_argument(
        "--max-reviews",
        dest="max_reviews",
        type=int,
        default=None,
        metavar="N",
        help="å„ã‚µã‚¤ãƒˆã®å–å¾—ä¸Šé™ä»¶æ•°ï¼ˆçœç•¥æ™‚ã¯èµ·å‹•æ™‚ã«å¯¾è©±ç¢ºèªï¼‰",
    )
    return parser.parse_args()


def _ask_max_reviews(site_name: str, cli_value: int | None) -> int | None:
    """ã‚µã‚¤ãƒˆã”ã¨ã®å–å¾—ä¸Šé™ã‚’ç¢ºèªã™ã‚‹ã€‚CLI ã§æŒ‡å®šæ¸ˆã¿ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™ã€‚"""
    if cli_value is not None:
        return cli_value
    while True:
        raw = input(f"\nğŸ“Š {site_name} ã®å–å¾—ä¸Šé™ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä»¶æ•°ã‚’å…¥åŠ› / Enterã§ç„¡åˆ¶é™ï¼‰: ").strip()
        if raw == "":
            print(f"  â†’ ç„¡åˆ¶é™ã§å–å¾—ã—ã¾ã™")
            return None
        if raw.isdigit() and int(raw) > 0:
            limit = int(raw)
            print(f"  â†’ ä¸Šé™ {limit} ä»¶ã§å–å¾—ã—ã¾ã™")
            return limit
        print("  âš ï¸ æ­£ã®æ•´æ•°ã‚’å…¥åŠ›ã™ã‚‹ã‹ã€Enterã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")


async def run_scrapers(args: argparse.Namespace, limits: dict[str, int | None]) -> list[dict]:
    """æŒ‡å®šã•ã‚ŒãŸ URL ã‹ã‚‰ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã€å…¨å£ã‚³ãƒŸã‚’è¿”ã™ã€‚"""
    from scrapers import scrape_google_maps, scrape_tabelog, scrape_tripadvisor

    all_reviews: list[dict] = []

    if args.google_maps:
        try:
            reviews = await scrape_google_maps(args.google_maps, max_reviews=limits["google_maps"])
            all_reviews.extend(reviews)
        except Exception as e:
            print(f"âš ï¸ Google ãƒãƒƒãƒ— ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")

    if args.tabelog:
        try:
            reviews = await scrape_tabelog(args.tabelog, max_reviews=limits["tabelog"])
            all_reviews.extend(reviews)
        except Exception as e:
            print(f"âš ï¸ é£Ÿã¹ãƒ­ã‚° ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")

    if args.tripadvisor:
        try:
            reviews = await scrape_tripadvisor(args.tripadvisor, max_reviews=limits["tripadvisor"])
            all_reviews.extend(reviews)
        except Exception as e:
            print(f"âš ï¸ TripAdvisor ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")

    return all_reviews


def main() -> None:
    args = parse_args()

    # URL ã‚‚ã‚¹ã‚­ãƒƒãƒ—ãƒ•ãƒ©ã‚°ã‚‚æŒ‡å®šãªã—
    if not args.skip_scrape and not any([args.google_maps, args.tabelog, args.tripadvisor]):
        print("âŒ ã‚¨ãƒ©ãƒ¼: --google-maps / --tabelog / --tripadvisor ã®ã„ãšã‚Œã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        print("   æ—¢å­˜ JSON ã‹ã‚‰å†åˆ†æã™ã‚‹å ´åˆã¯ --skip-scrape ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)

    raw_json_path = "reviews_raw.json"
    analyzed_json_path = "reviews_analyzed.json"

    # ---- å–å¾—ä¸Šé™ã®ç¢ºèªï¼ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œæ™‚ã®ã¿ï¼‰----
    limits: dict[str, int | None] = {"google_maps": None, "tabelog": None, "tripadvisor": None}
    if not args.skip_scrape:
        print("\nğŸ“‹ å–å¾—ä¸Šé™ã®è¨­å®š")
        if args.google_maps:
            limits["google_maps"] = _ask_max_reviews("Google ãƒãƒƒãƒ—", args.max_reviews)
        if args.tabelog:
            limits["tabelog"] = _ask_max_reviews("é£Ÿã¹ãƒ­ã‚°", args.max_reviews)
        if args.tripadvisor:
            limits["tripadvisor"] = _ask_max_reviews("TripAdvisor", args.max_reviews)

    # ---- ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° ----
    if args.skip_scrape:
        if not os.path.exists(raw_json_path):
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {raw_json_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            sys.exit(1)
        print(f"â­ï¸  ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã€‚{raw_json_path} ã‚’èª­ã¿è¾¼ã¿ã¾ã™...")
        with open(raw_json_path, encoding="utf-8") as f:
            all_reviews = json.load(f)
        print(f"  ğŸ“‚ {len(all_reviews)}ä»¶ã®å£ã‚³ãƒŸã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
    else:
        print(f"\nğŸš€ å£ã‚³ãƒŸåé›†ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆåº—èˆ—å: {args.name}ï¼‰\n")
        all_reviews = asyncio.run(run_scrapers(args, limits))

        if not all_reviews:
            print("âš ï¸ å£ã‚³ãƒŸãŒ1ä»¶ã‚‚å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚URL ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            sys.exit(1)

        with open(raw_json_path, "w", encoding="utf-8") as f:
            json.dump(all_reviews, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ {len(all_reviews)}ä»¶ã®å£ã‚³ãƒŸã‚’ {raw_json_path} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

    # ---- Gemini åˆ†æ ----
    from analyzer import analyze_reviews

    analysis = analyze_reviews(all_reviews)

    with open(analyzed_json_path, "w", encoding="utf-8") as f:
        json.dump(analysis, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ åˆ†æçµæœã‚’ {analyzed_json_path} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

    # ---- HTML ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ ----
    from reporter import generate_report

    generate_report(args.name, analysis, output_path=args.output)

    # ---- Netlify ã¸è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤ ----
    print("\nğŸ“¤ Netlify ã¸è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤ä¸­...")
    share_sh = os.path.join(os.path.dirname(os.path.abspath(__file__)), "share.sh")
    result = subprocess.run(["bash", share_sh, args.name], capture_output=False)
    if result.returncode != 0:
        print("âš ï¸ ãƒ‡ãƒ—ãƒ­ã‚¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§ bash share.sh ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")


if __name__ == "__main__":
    main()
